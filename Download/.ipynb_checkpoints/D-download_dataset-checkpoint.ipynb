{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fcb3e9f-967f-4edf-a11b-6870a2775d36",
   "metadata": {
    "id": "A547k4aK4Wpe",
    "tags": []
   },
   "source": [
    "# **D-download_dataset.ipynb**\n",
    "\n",
    "Author: Zhixian Yang\n",
    "\n",
    "Email: [yangzhx28@mail2.sysu.edu.cn](mailto:yangzhx28@mail2.sysu.edu.cn) or [yimu01439@gmail.com](mailto:yimu01439@gmail.com)\n",
    "\n",
    "GitHub: [https://github.com/koar-create](https://github.com/koar-create)\n",
    "\n",
    "Date created: July 20th, 2023\n",
    "\n",
    "Last modified: July 26th, 2023\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## **Description**\n",
    "This document is a Jupyter Notebook designed for an exercise derived from the \"Computational Tools for Climate Science 2023\" course offered by Climatematch Academy. The code presented here comprises a combination of materials provided in the course and code obtained from online sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c826e-21a7-461e-a899-9917431876ad",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# **<font size=5 color='F00000'>download dependencies, import packages</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb5612-c914-4545-aa56-f21f6e54495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi --quiet\n",
    "\n",
    "import cdsapi\n",
    "import urllib.request\n",
    "from itertools import product\n",
    "import s3fs, boto3, botocore, pooch\n",
    "from pythia_datasets import DATASETS\n",
    "import os, sys, glob, platform, tempfile\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import matplotlib as mpl, matplotlib.pyplot as plt\n",
    "import cartopy, cartopy.crs as ccrs, cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "import cartopy.io.shapereader as shapereader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf848be6-5e0d-411d-8c0b-82120019ff4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br></br>\n",
    "# **<font size=5 color='F00000'>download NCEP-NCAR version 1 ReAnalysis Dataset</font>**\n",
    "\n",
    "---\n",
    "\n",
    "**site:**\n",
    "- **https://downloads.psl.noaa.gov/Datasets/ncep.reanalysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203fd541-9c21-4806-b1f8-0aabec097e56",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**<font face=\"Times New Roman\" size=4 color='43B0D0'>Yang: here I define a function used to download NCEP-NCAR version 1 ReAnalysis dataset. The new function is defined to make it easier to specify the time domain, spatial domain, and resolution we want. You don't need to understand this code block lines by lines.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781c5dc-90b4-4cb1-8cd8-d0bf9a6fa821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Yang: Here I define a function used to download NCEP-NCAR version 1 ReAnalysis dataset. \n",
    "# You don't need to understand this code block lines by lines. \n",
    "def download_from_ncep(year=None, dataset='NCEP-NCAR-v1', \n",
    "                       temporal_res='monthly', level_type='pressure'):\n",
    "    variables  = {'surface': ['lftx.sfc', 'lftx4.sfc', 'pres.sfc', 'pr_wtr.eatm', 'slp'], \n",
    "                  'near_surface': [i + '.sig995' for i in ['air', 'omega', 'pottmp', 'rhum', 'uwnd', 'vwnd']], \n",
    "                  'pressure': ['air', 'hgt', 'omega', 'rhum', 'shum', 'uwnd', 'vwnd']}\n",
    "    extra_variables = {'surface': ['air', 'pres', 'pr_wtr', 'rhum', 'uwnd', 'vwnd', 'wspd', \n",
    "                                   'thickness', 'thickness_500200', 'thickness_850500', 'thickness_1000500'], \n",
    "                       'near_surface': ['wspd.sig995'], \n",
    "                       'pressure': ['wspd', 'pottmp']}\n",
    "    if temporal_res == 'monthly':\n",
    "        var_list = variables[level_type] + extra_variables[level_type]\n",
    "    else:\n",
    "        var_list = variables[level_type]\n",
    "    for var in var_list:\n",
    "        if   temporal_res == 'monthly':\n",
    "            add_flag = 'Monthlies/'\n",
    "            filename = f\"{var}.mon.mean.nc\"\n",
    "        elif temporal_res == 'daily':\n",
    "            add_flag = ''\n",
    "            filename = f\"{var}.{year}.nc\"\n",
    "        \n",
    "        url = f\"https://downloads.psl.noaa.gov/Datasets/ncep.reanalysis/{add_flag}{level_type}/{filename}\"\n",
    "        save_path = os.path.join(dataset, temporal_res, level_type)\n",
    "        url = url.replace('near_', '') if level_type == 'near_surface' else url  # don't need to know what it does\n",
    "        \n",
    "        # if the path to save the file does not exist, create it first. \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        # if the file does not exist, download it. \n",
    "        if not os.path.exists(os.path.join(save_path, filename)):\n",
    "            try:\n",
    "                print(f'Downloading {url}...')\n",
    "                urllib.request.urlretrieve(url, os.path.join(save_path, filename))\n",
    "            except:\n",
    "                print(f'{url} does not exist. ')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da35f36-186c-42d8-992d-c80c2f67b39f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<font face=\"Times New Roman\" size=4 color='43B0D0'>Yang: ↓ this is the code block used to download data. specify the start year, end year, level type (`surface`, `near_surface` or `pressure`) and temporal resolution (`daily` or `monthly`).</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6923882-59c6-4c35-bf42-ace1a0b67721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "level_type = 'pressure'\n",
    "temporal_res = 'monthly'\n",
    "start_year, end_year = 1995, 2000\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    download_from_ncep(level_type=level_type, \n",
    "                       year=year, temporal_res=temporal_res, \n",
    "                       dataset='NCEP-NCAR-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc62a7-d0b8-403e-bb33-7698caab4bfa",
   "metadata": {},
   "source": [
    "**<font face=\"Times New Roman\" size=4 color='43B0D0'>Yang: ↓ these are the code blocks used to read the downloaded data. (you can try to unfold some of them)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df3a4d-2e5e-4d58-9189-ede2fe026ed8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'daily'\n",
    "start_year, end_year = 1995, 2000\n",
    "sfc_var_list  = ['lftx.sfc', 'lftx4.sfc', 'pres.sfc', 'pr_wtr.eatm', 'slp']\n",
    "\n",
    "for idx, var in enumerate(sfc_var_list):\n",
    "    ds_list = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        file_path = os.path.join('NCEP-NCAR-v1', 'daily', 'surface', f\"{var}.{year}.nc\")\n",
    "        ds_temp = xr.open_dataset(file_path)\n",
    "        ds_list.append(ds_temp.sel(time=ds_temp.time.dt.hour == 0))\n",
    "        del ds_temp\n",
    "    ds_temp = xr.concat(ds_list, dim='time')\n",
    "    ds_sfc_daily = ds_temp if idx == 0 else xr.merge([ds_sfc_daily, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e45f5f-8ff9-46dd-aa54-b2f9961cf363",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'daily'\n",
    "start_year, end_year = 1995, 2000\n",
    "nsfc_var_list = [i + '.sig995' for i in ['air', 'omega', 'pottmp', 'rhum', 'uwnd', 'vwnd']]\n",
    "\n",
    "for idx, var in enumerate(nsfc_var_list):\n",
    "    ds_list = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        file_path = os.path.join('NCEP-NCAR-v1', 'daily', 'near_surface', f\"{var}.{year}.nc\")\n",
    "        ds_temp = xr.open_dataset(file_path)\n",
    "        ds_list.append(ds_temp.sel(time=ds_temp.time.dt.hour == 0))\n",
    "        del ds_temp\n",
    "    ds_temp = xr.concat(ds_list, dim='time')\n",
    "    ds_nsfc_daily = ds_temp if idx == 0 else xr.merge([ds_nsfc_daily, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cea51a-25ce-4be4-aa03-50cf2bc8e288",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'daily'\n",
    "start_year, end_year = 1995, 2000\n",
    "pres_var_list = ['air', 'hgt', 'omega', 'rhum', 'shum', 'uwnd', 'vwnd']\n",
    "\n",
    "for idx, var in enumerate(pres_var_list):\n",
    "    ds_list = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        file_path = os.path.join('NCEP-NCAR-v1', 'daily', 'pressure', f\"{var}.{year}.nc\")\n",
    "        ds_temp = xr.open_dataset(file_path)\n",
    "        ds_list.append(ds_temp.sel(time=ds_temp.time.dt.hour == 0))\n",
    "        del ds_temp\n",
    "    ds_temp = xr.concat(ds_list, dim='time')\n",
    "    ds_pres_daily = ds_temp if idx == 0 else xr.merge([ds_pres_daily, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b4b43-d31c-43c8-8dee-06d740b58073",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = '2000-12-01'\n",
    "level = 1000.0\n",
    "var = ds3.omega.sel(time=time, level=level, lat=slice(10, -15), lon=slice(90, 130)).squeeze()\n",
    "\n",
    "proj = ccrs.Mercator(central_longitude=110.0)\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': proj})\n",
    "im = ax.contourf(var.lon, var.lat, var, transform=ccrs.PlateCarree(), \n",
    "                 levels=np.linspace(-0.4, 0.4, 11), extend='both', cmap='coolwarm')\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, color='k', alpha=0.8, linewidth=0.8, linestyle='dashed')\n",
    "gl.xformatter, gl.yformatter = LongitudeFormatter(), LatitudeFormatter()\n",
    "gl.top_labels = False\n",
    "\n",
    "ax.coastlines()\n",
    "ax.set_title(f\"{var.attrs['var_desc']}, {level:.0f} hPa, {time}\")\n",
    "\n",
    "fig.colorbar(im, label='units: Pa/s', orientation='horizontal', \n",
    "             ticks=np.linspace(-0.4, 0.4, 11), extend='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fe1477-3ff4-4ff1-8759-18c589c82545",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'monthly'\n",
    "sfc_var_list  = ['lftx.sfc', 'lftx4.sfc', 'pres.sfc', 'pr_wtr.eatm', 'slp', 'air', 'pres', 'pr_wtr', 'rhum', 'uwnd', 'vwnd', 'wspd', \n",
    "                 'thickness', 'thickness_500200', 'thickness_850500', 'thickness_1000500']\n",
    "\n",
    "for idx, var in enumerate(sfc_var_list):\n",
    "    file_path = os.path.join('NCEP-NCAR-v1', 'monthly', 'surface', f\"{var}.mon.mean.nc\")\n",
    "    ds_temp = xr.open_dataset(file_path)\n",
    "    ds_sfc_monthly = ds_temp if idx == 0 else xr.merge([ds_sfc_monthly, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac9fcc-a148-477e-a1ac-4e880ee131ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'monthly'\n",
    "nsfc_var_list  = [i + '.sig995' for i in ['air', 'omega', 'pottmp', 'rhum', 'uwnd', 'vwnd', 'wspd']]\n",
    "\n",
    "for idx, var in enumerate(nsfc_var_list):\n",
    "    file_path = os.path.join('NCEP-NCAR-v1', 'monthly', 'near_surface', f\"{var}.mon.mean.nc\")\n",
    "    ds_temp = xr.open_dataset(file_path)\n",
    "    ds_nsfc_monthly = ds_temp if idx == 0 else xr.merge([ds_nsfc_monthly, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325798ae-dced-455b-9c80-67c3118976c5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_res = 'monthly'\n",
    "pres_var_list  = ['air', 'hgt', 'omega', 'rhum', 'shum', 'uwnd', 'vwnd', 'wspd', 'pottmp']\n",
    "\n",
    "for idx, var in enumerate(pres_var_list):\n",
    "    file_path = os.path.join('NCEP-NCAR-v1', 'monthly', 'surface', f\"{var}.mon.mean.nc\")\n",
    "    ds_temp = xr.open_dataset(file_path)\n",
    "    ds_pres_monthly = ds_temp if idx == 0 else xr.merge([ds_pres_monthly, ds_temp])\n",
    "    del ds_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766983d1-4ad2-4b00-87e5-4435e6fce618",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **<font size=5 color='Magenta'>ERA5</font>**\n",
    "\n",
    "---\n",
    "\n",
    "**site:**\n",
    "- **land-only, hourly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land**\n",
    "- **land-only, monthly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-land-monthly-means**\n",
    "- **single level, hourly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels**\n",
    "- **single level, monthly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels-monthly-means**\n",
    "- **pressure levels, hourly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels**\n",
    "- **pressure levels, monthly: https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-pressure-levels-monthly-means**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c88a9-87ed-4af3-b140-7a7f8e08aae1",
   "metadata": {
    "tags": []
   },
   "source": [
    "**<font face=\"Times New Roman\" size=4 color='43D0B0'>Yang: To download ERA-5 ReAnalysis data offered by ECMWF (European Centre for Medium-Range Weather Forecasts), you need to register an account [here](https://cds.climate.copernicus.eu/user/register?destination=/), and obtain your private key [here](https://cds.climate.copernicus.eu/api-how-to). I hide my private key, so you're actually unable to run code blocks in this part. </font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de02c90c-9475-4b70-bd71-e3e949ef5f9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "**<font face=\"Times New Roman\" size=4 color='43B0D0'>Yang: here I define a function used to download ERA-5 ReAnalysis dataset. Also, you don't need to understand this code block lines by lines.</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd6673-549e-4d57-9e05-d123f0daf64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'S': ['10m_u_component_of_wind', '10m_v_component_of_wind', '100m_u_component_of_wind', '100m_v_component_of_wind', \n",
    "#                        'skin_temperature', '2m_temperature', 'sea_surface_temperature', \n",
    "#                        'surface_pressure', 'mean_sea_level_pressure', \n",
    "#                        'convective_precipitation', 'convective_rain_rate', 'large_scale_precipitation', 'large_scale_rain_rate', 'total_precipitation'],\n",
    "\n",
    "def download_from_ecmwf(mode='LM', extra_flag=\"no\", fname=None, \n",
    "                        years=None, months=None, days=None, times=None, \n",
    "                        area=[90, -180, -90, 180], pressures=None):\n",
    "    !echo \"url: https://cds.climate.copernicus.eu/api/v2\" > $HOME/.cdsapirc\n",
    "    !echo \"key: ...:...\" >> $HOME/.cdsapirc\n",
    "    !cat $HOME/.cdsapirc\n",
    "    temporal_res = {'H': 'hourly', 'M': 'monthly'}\n",
    "    level_type   = {'L': 'land'  , 'S': 'single_level', 'P': 'pressure_levels'}\n",
    "    file_name = os.path.join(\"ERA5\", temporal_res[mode[-1]], level_type[mode[0]], fname)\n",
    "    line1 = {'LH':            'land', 'LM':            'land-monthly-means',\n",
    "             'SH':   'single-levels', 'SM':   'single-levels-monthly-means',\n",
    "             'PH': 'pressure-levels', 'PM': 'pressure-levels-monthly-means'}\n",
    "    product_type = {'H': 'reanalysis', 'M': 'monthly_averaged_reanalysis'}\n",
    "    variables = {'L': ['10m_u_component_of_wind', '10m_v_component_of_wind', \n",
    "                       'skin_temperature', '2m_temperature', \n",
    "                       'surface_pressure', \n",
    "                       'total_precipitation'], \n",
    "                 'S': ['10m_u_component_of_wind', '10m_v_component_of_wind', \n",
    "                       'sea_surface_temperature', \n",
    "                       'mean_sea_level_pressure'],\n",
    "                 'P': ['u_component_of_wind', 'v_component_of_wind', 'vertical_velocity', \n",
    "                        'temperature', \n",
    "                        'geopotential', \n",
    "                        'relative_humidity', 'specific_humidity']}\n",
    "    extra_variables = {\"yes\": {'L': ['2m_dewpoint_temperature'],\n",
    "                               'S': ['2m_dewpoint_temperature', 'convective_available_potential_energy', \n",
    "                                     'mean_vertically_integrated_moisture_divergence'],\n",
    "                               'P': ['divergence', 'fraction_of_cloud_cover', 'ozone_mass_mixing_ratio', \n",
    "                                     'potential_vorticity', 'specific_cloud_ice_water_content', \n",
    "                                     'specific_cloud_liquid_water_content', 'specific_rain_water_content', \n",
    "                                     'specific_snow_water_content', 'vorticity', ], },\n",
    "                       \"no\": {'L': [], 'S': [], 'P': [], }}\n",
    "    pressure_level = {'pressure_level': pressures}\n",
    "    dict_day = {'day': days}\n",
    "    \n",
    "    c = cdsapi.Client()\n",
    "    retrieve_dict = {\n",
    "        'product_type': product_type[mode[-1]],\n",
    "        'variable': variables[mode[0]] + extra_variables[extra_flag][mode[0]],\n",
    "        'year': years,\n",
    "        'month': months,\n",
    "        'time': times,\n",
    "        'format': 'netcdf',\n",
    "        'area': area}\n",
    "    if mode == 'LH':\n",
    "        retrieve_dict = {key: value for key, value in retrieve_dict.items() if key not in {'product_type': []}}\n",
    "    if mode[0] == 'P':\n",
    "        retrieve_dict.update(pressure_level)\n",
    "    if mode[1] == 'H':\n",
    "        retrieve_dict.update(dict_day)\n",
    "    if not os.path.exists(os.path.dirname(file_name)):\n",
    "        os.makedirs(os.path.dirname(file_name))\n",
    "    if not os.path.exists(file_name):\n",
    "        c.retrieve(f\"reanalysis-era5-{line1[mode]}\", retrieve_dict , file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e4211a-43e4-458c-8053-03c3b56b61db",
   "metadata": {},
   "source": [
    "**<font size=4>Yang: ↓ this is the code block used to download data. specify the start year, end year, mode (`LH`, `LM`, `SH`, `SM`, `PH`, `PM`) and pressures (usually `['1000']` is ok).</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4917d1-1c70-41c0-9279-d705b3ccf6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify the start year, end year, mode, and pressure level (if you choose 'pressure levels'). \n",
    "start_year, end_year = 1996, 2000\n",
    "mode  = 'SM' # 'S' means 'single', 'M' means 'monthly', so there're {'L', 'S', 'P'}x{'H', 'M'} = 6 groups\n",
    "pressures = ['1000']\n",
    "\n",
    "# don't change these codes:\n",
    "fname = f\"{start_year}-{end_year}_{mode}.nc\"\n",
    "extra_flag = \"no\"\n",
    "years = [str(year) for year in range(start_year, end_year + 1)]\n",
    "months = [f\"{month:02}\" for month in range(1, 12 + 1)]\n",
    "days = [f\"{day:02}\" for day in range(1, 31 + 1)]\n",
    "times = ['00:00']\n",
    "area = [60, -180, -60, 180]\n",
    "\n",
    "# call the function. \n",
    "download_from_ecmwf(mode=mode, extra_flag=\"no\", fname=fname, \n",
    "                    years=years, months=months, days=days, times=times, \n",
    "                    area=area, pressures=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fdec6-c719-42e6-8b64-f81f31badfe5",
   "metadata": {},
   "source": [
    "**<font size=4>Yang: ↓ these are the code blocks used to read the downloaded data. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3dd613-2d6a-453b-87e5-dfee05d9b98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = os.path.join('ERA5', 'hourly', 'single_level', '1996-2005.SH.nc')\n",
    "ds = xr.open_dataset(file_path).squeeze()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace0669-3feb-44fc-a0a4-04237d909cde",
   "metadata": {},
   "source": [
    "**<font size=4>Yang: ↓ these are the code blocks used to visualize data. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9b346-53d2-4407-8d9e-81ac4f719049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# time = '2000-12-01'\n",
    "# level = 1000.0\n",
    "var = ds4.lsrr.sel(latitude=slice(10, -15), longitude=slice(90, 130)).squeeze()\n",
    "\n",
    "proj = ccrs.Mercator(central_longitude=110.0)\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': proj})\n",
    "im = ax.contourf(var.longitude, var.latitude, 86400.0 * var, transform=ccrs.PlateCarree(), \n",
    "                 levels=np.linspace(0, 15, 11), extend='both', cmap='coolwarm')\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, x_inline=False, y_inline=False, color='k', alpha=0.8, linewidth=0.8, linestyle='dashed')\n",
    "gl.xformatter, gl.yformatter = LongitudeFormatter(), LatitudeFormatter()\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "ax.coastlines()\n",
    "ax.set_title(f\"{var.attrs['long_name']}, 2016-01-01\")\n",
    "\n",
    "fig.colorbar(im, label='units: m/day', orientation='horizontal', \n",
    "             ticks=np.linspace(0, 15, 11), extend='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c126f-876a-4a1f-a27e-801a6dc66470",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **<font size=5 color='cyan'>TRMM</font>**\n",
    "\n",
    "---\n",
    "\n",
    "**site:**\n",
    "- **Register here first: https://registration.pps.eosdis.nasa.gov/registration/newContact.html**\n",
    "- **After registration, you can access data here with username and password (both are the email you use to register: https://arthurhouhttps.pps.eosdis.nasa.gov/**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c22df2-c582-4387-8eaa-52a06676bcd5",
   "metadata": {},
   "source": [
    "**<font size=4>Yang: You don't need to understand this code block, and don't try to run it (to successfully run it, you need to make some adaptations).</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293d512-c0ae-402f-8b5b-f7822388383d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import os, time\n",
    "\n",
    "username = '...'\n",
    "password = '...'\n",
    "\n",
    "start_year, end_year = 2001, 2002\n",
    "for year in range(start_year, end_year + 1):\n",
    "    version = '7' if ((year < 2000)|(year > 2010)) else '7A'\n",
    "    for month in range(1, 12 + 1):\n",
    "        for day in range(1, 31 + 1):\n",
    "            for hour in range(0, 3, 3):\n",
    "                url = f\"https://arthurhouhttps.pps.eosdis.nasa.gov/trmmdata/ByDate/V07/{year}/{month:02}/{day:02}/3B42.{year}{month:02}{day:02}.{hour:02}.7A.HDF5\"\n",
    "                save_path = os.path.join('TRMM', '3B42', f\"{year}\", f\"{month:02}\", f\"{day:02}\", f\"3B42.{year}{month:02}{day:02}.{hour:02}.7A.HDF5\")\n",
    "                \n",
    "                # Create a password manager and add the username and password\n",
    "                password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "                password_mgr.add_password(None, url, username, password)\n",
    "\n",
    "                # Create a basic authentication handler\n",
    "                auth_handler = urllib.request.HTTPBasicAuthHandler(password_mgr)\n",
    "\n",
    "                # Create an opener and install the authentication handler\n",
    "                opener = urllib.request.build_opener(auth_handler)\n",
    "\n",
    "                # Install the opener to be used by urlretrieve\n",
    "                urllib.request.install_opener(opener)\n",
    "\n",
    "                # Download the file using urlretrieve\n",
    "                if not os.path.exists(os.path.dirname(save_path)):\n",
    "                    os.makedirs(os.path.dirname(save_path))\n",
    "                if not os.path.exists(save_path):\n",
    "                    try:\n",
    "                        urllib.request.urlretrieve(url, filename=save_path)\n",
    "                        time.sleep(0.1)\n",
    "                    except:\n",
    "                        print(f\"{save_path.split('/')[-1]} doesn't not exist. \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
